"""
This type stub file was generated by pyright.
"""

from typing import Any, Tuple

import numpy
from .. import h5d
from .base import HLObject, with_phil
from .vds import vds_support

"""
    Implements support for high"""
_LEGACY_GZIP_COMPRESSION_VALS = ...
MPI = ...
def make_new_dset(parent, shape=..., dtype=..., data=..., name=..., chunks=..., compression=..., shuffle=..., fletcher32=..., maxshape=..., compression_opts=..., fillvalue=..., scaleoffset=..., track_times=..., external=..., track_order=..., dcpl=..., allow_unknown_filter=...):
    """ Return a new low-level dataset """
    ...

class AstypeWrapper:
    """Wrapper to convert data on readi"""
    def __init__(self, dset, dtype) -> None:
        ...

    def __getitem__(self, args):
        ...

    def __enter__(self): # -> Self@AstypeWrapper:
        ...

    def __exit__(self, *args): # -> None:
        ...

    def __len__(self): # -> int:
        """ Get the length of the underlyin"""
        ...



class AsStrWrapper:
    """Wrapper to decode strings on rea"""
    def __init__(self, dset, encoding, errors=...) -> None:
        ...

    def __getitem__(self, args): # -> ndarray[Any, Unknown]:
        ...

    def __len__(self): # -> int:
        """ Get the length of the underlyin"""
        ...



class FieldsWrapper:
    """Wrapper to extract named fields """
    extract_field = ...
    def __init__(self, dset, prior_dtype, names) -> None:
        ...

    def __getitem__(self, args):
        ...

    def __len__(self): # -> int:
        """ Get the length of the underlyin"""
        ...



def readtime_dtype(basetype, names): # -> dtype[void]:
    """Make a NumPy compound dtype with"""
    ...

if MPI:
    class CollectiveContext:
        """ Manages collective I/O in MPI m"""
        def __init__(self, dset) -> None:
            ...

        def __enter__(self): # -> None:
            ...

        def __exit__(self, *args): # -> None:
            ...



class ChunkIterator:
    """
    Class to iterate through li"""
    def __init__(self, dset, source_sel=...) -> None:
        ...

    def __iter__(self): # -> Self@ChunkIterator:
        ...

    def __next__(self): # -> tuple[Unknown, ...]:
        ...



class Dataset(HLObject):
    """
        Represents an HDF5 data"""
    def astype(self, dtype): # -> AstypeWrapper:
        """ Get a wrapper allowing you to p"""
        ...

    def asstr(self, encoding=..., errors=...): # -> AsStrWrapper:
        """Get a wrapper to read string dat"""
        ...

    def fields(self, names, *, _prior_dtype=...): # -> FieldsWrapper:
        """Get a wrapper to read a subset o"""
        ...

    if MPI:
        @property
        @with_phil
        def collective(self): # -> CollectiveContext:
            """ Context manager for MPI collect"""
            ...

    @property
    def dims(self): # -> DimensionManager:
        """ Access dimension scales attache"""
        ...

    @property
    @with_phil
    def ndim(self):
        """Numpy-style attribute giving the"""
        ...

    @property
    def shape(self) -> Tuple[int, ...]:
        """Numpy-style shape tuple giving d"""
        ...

    @shape.setter
    # @with_phil
    def shape(self, shape: Tuple[int, ...]):
        ...

    @property
    def size(self): # -> Any | None:
        """Numpy-style attribute giving the"""
        ...

    @property
    def nbytes(self): # -> Literal[0]:
        """Numpy-style attribute giving the"""
        ...

    @property
    @with_phil
    def dtype(self) -> "numpy.dtype[Any]":
        """Numpy dtype representing the dat"""
        ...

    @property
    # @with_phil
    def chunks(self) -> "Tuple[int, ...] | None":
        """Dataset chunks (or None)"""
        ...

    @property
    @with_phil
    def compression(self): # -> str | None:
        """Compression strategy (or None)"""
        ...

    @property
    @with_phil
    def compression_opts(self): # -> None:
        """ Compression setting.  Int(0-9) """
        ...

    @property
    @with_phil
    def shuffle(self): # -> bool:
        """Shuffle filter present (T/F)"""
        ...

    @property
    @with_phil
    def fletcher32(self): # -> bool:
        """Fletcher32 filter is present (T/"""
        ...

    @property
    @with_phil
    def scaleoffset(self): # -> None:
        """Scale/offset filter settings. Fo"""
        ...

    @property
    @with_phil
    def external(self): # -> list[Unknown] | None:
        """External file settings. Returns """
        ...

    @property
    @with_phil
    def maxshape(self): # -> tuple[Unknown | None, ...] | None:
        """Shape up to which this dataset c"""
        ...

    @property
    @with_phil
    def fillvalue(self): # -> Any:
        """Fill value for this dataset (0 b"""
        ...

    @with_phil
    def __init__(self, bind, *, readonly=...) -> None:
        """ Create a new Dataset object by """
        ...

    def resize(self, size, axis=...): # -> None:
        """ Resize the dataset, or the spec"""
        ...

    @with_phil
    def __len__(self):
        """ The size of the first axis.  Ty"""
        ...

    def len(self):
        """ The size of the first axis.  Ty"""
        ...

    @with_phil
    def __iter__(self): # -> Generator[Unknown, None, None]:
        """ Iterate over the first axis.  T"""
        ...

    @with_phil
    def iter_chunks(self, sel=...): # -> ChunkIterator:
        """ Return chunk iterator.  If set,"""
        ...

    @with_phil
    def __getitem__(self, args, new_dtype=...) -> "numpy.ndarray[Any, Any] | bytes": #FIXME: could this return something else?
        """ Read a slice from the HDF5 data"""
        ...

    @with_phil
    def __setitem__(self, args, val):
        """ Write to the HDF5 dataset from """
        ...

    def read_direct(self, dest, source_sel=..., dest_sel=...): # -> None:
        """ Read data directly from HDF5 in"""
        ...

    def write_direct(self, source, source_sel=..., dest_sel=...): # -> None:
        """ Write data directly to HDF5 fro"""
        ...

    @with_phil
    def __array__(self, dtype=...): # -> ndarray[Unknown, Unknown]:
        """ Create a Numpy array containing"""
        ...

    @with_phil
    def __repr__(self): # -> str:
        ...

    if hasattr(h5d.DatasetID, "refresh"):
        @with_phil
        def refresh(self): # -> None:
            """ Refresh the dataset metadata by"""
            ...

    if hasattr(h5d.DatasetID, "flush"):
        @with_phil
        def flush(self): # -> None:
            """ Flush the dataset data and meta"""
            ...

    if vds_support:
        @property
        @with_phil
        def is_virtual(self):
            """Check if this is a virtual datas"""
            ...

        @with_phil
        def virtual_sources(self): # -> list[VDSmap]:
            """Get a list of the data mappings """
            ...

    @with_phil
    def make_scale(self, name=...): # -> None:
        """Make this dataset an HDF5 dimens"""
        ...



